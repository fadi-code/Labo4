# Pipeline de Données de Bout en Bout sur Azure

## Vue d'Ensemble
Ce document présente une solution complète d'ingénierie des données sur Azure. Ce projet intègre divers services Azure pour orchestrer, transformer et visualiser les données. La pipeline utilise :

- **Azure Data Factory (ADF)** pour l'orchestration des données,
- **Azure Databricks** pour la transformation des données avec des notebooks PySpark,
- **Azure Synapse Analytics** pour l'entreposage des données,
- **Power BI** pour la visualisation.

## Structure du Projet
Le projet est organisé autour des composants suivants :

- **Key Vault** : Gestion des secrets pour éviter le stockage d'informations sensibles dans le code.
- **Azure Storage Account** : Stockage cloud évolutif et durable.
- **Azure Data Factory (ADF)** : Orchestration des flux de données et exécution des notebooks Databricks.
- **Azure Databricks** : Traitement des données (bronze -> silver -> gold).
- **Azure Synapse Analytics** : Entrepôt de données.
- **Power BI** : Visualisation interactive des données.

## Prérequis
Avant de commencer, assurez-vous d'avoir :

- Un abonnement Azure avec les permissions nécessaires.
- Accès à Azure Data Factory, Azure Databricks, Azure Synapse Analytics et Power BI.
- Une compréhension de base des services Azure et des concepts d'ingénierie des données.

## Mise en Place du Projet

### 1. Téléchargement et Restauration de la Base de Données AdventureWorksLT2017

- **Télécharger la base de données** : Obtenez AdventureWorksLT2017 depuis le lien officiel.
- **Restaurer la base de données** : Suivez les instructions pour restaurer la base sur votre instance SQL Server.

### 2. Configuration d'Azure Data Factory (ADF)
Azure Data Factory orchestre le mouvement des données et l'exécution des transformations.

#### Création d'un Pipeline de Données

##### Accéder à ADF Studio :
- Se rendre sur le portail Azure et ouvrir ADF.
- Cliquer sur "Author & Monitor".

##### Créer un pipeline :
- Aller dans "Author" et cliquer sur "New pipeline".
- Nommer le pipeline de manière significative.

##### Ajouter et configurer des activités :
- Ajouter des activités comme "Copy Data", "Data Flow" et "Lookup".
- Définir les sources et destinations.

#### Configuration des Sources de Données

##### Services liés :
- Aller dans "Manage" > "Linked services".
- Ajouter des connexions (Azure SQL, Blob Storage, etc.).

##### Jeux de données :
- Définir les datasets source et destination.
- Configurer les mappings de schéma.
